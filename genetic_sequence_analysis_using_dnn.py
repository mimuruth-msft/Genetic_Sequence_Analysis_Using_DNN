# -*- coding: utf-8 -*-
"""Genetic_Sequence_Analysis_Using_DNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/mmrepos/Genetic_Sequence_Analysis_Using_DNN/blob/main/Genetic_Sequence_Analysis_Using_DNN.ipynb
    Entire project can be viewed in github at: https://github.com/mmrepos/Genetic_Sequence_Analysis_Using_DNN
"""

#####################################################################################################################
#
#   Genetic sequence analysis using deep neural network analysis
#
#####################################################################################################################

import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, MinMaxScaler
from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, GridSearchCV
import warnings
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore', module='sklearn')
warnings.filterwarnings('ignore', module='IPython')

# Load the clinvar_conflicting.csv files and assign the variable name dataFile
dataFile = pd.read_csv\
(f'https://raw.githubusercontent.com/mmrepos/'\
'Genetic_Sequence_Analysis_Using_DNN/main/'
'Dataset/clinvar_conflicting.csv')
# Inspect the first ten records in the DataFrame
dataFile.head(10)

dataFile.shape

dataFile.CLASS.value_counts()

# get unique values of a column in a Pandas dataframe
pd.DataFrame([[i, len(dataFile[i].unique())] 
              for i in dataFile.columns],
             columns=['Variable', 'Unique Values']).set_index('Variable')

#
unique_columns = pd.DataFrame([[i, len(dataFile[i].unique())] for i in
                              dataFile.columns], columns=['Variable',
                              'Unique Values']).set_index('Variable')
to_drop = list(unique_columns[unique_columns['Unique Values']
               > 3000].index)
dataFile.drop(to_drop, axis=1, inplace=True)

# get unique values of a column in a Pandas dataframe
pd.DataFrame([[i, len(dataFile[i].unique())] 
              for i in dataFile.columns],
             columns=['Variable', 'Unique Values']).set_index('Variable')

#
unique_columns = pd.DataFrame([[i, len(dataFile[i].unique())] for i in
                              dataFile.columns], columns=['Variable',
                              'Unique Values']).set_index('Variable')
to_drop = list(unique_columns[unique_columns['Unique Values']
               > 3000].index)
dataFile.drop(to_drop, axis=1, inplace=True)

pd.DataFrame([[i, len(dataFile[i].unique())] for i in dataFile.columns],
             columns=['Variable', 'Unique Values']).set_index('Variable'
        )

# Check and manage NULL values in the data frame.

number_missing = dataFile.isnull().sum()
percentage_missing = dataFile.isnull().sum().apply(lambda x: x \
        / dataFile.shape[0] * 100)

data_missing = pd.DataFrame({'Number Missing': number_missing,
                            'Percentage Missing': percentage_missing})

# Percentage of missing data in the dataframe in descending order

data_missing['Percentage Missing'].sort_values(ascending=False)

# Drop the columns where >= 20% of the data is missing

list_to_drop = list(data_missing[data_missing['Percentage Missing']
                 >= 20].index)
dataFile.drop(list_to_drop, axis=1, inplace=True)

# Check the NULL values in a data frame.

dataFile.isnull().sum()

# Create a new figure with the specified width and height
# Display dataFrame as heatmap

plt.figure(figsize=(12, 10))
sns.heatmap(dataFile.corr(), annot=True, linewidths=.5, cmap=plt.cm.cool)

# Drop the AF_TGP column that is strongly correlated
# Correlation for AF_ESP with AF_TGP is above 0.8

dataFile.drop(['AF_TGP'],axis = 1, inplace=True)

# Return the data type of each column in the DataFrame
# count the number of missing values instead.
# dataFile.isnull().sum() returns the number of missing values for each column

df_data = pd.DataFrame(dataFile.isnull().sum().astype(int),
                       columns=['Null'])
nullList = list(df_data[df_data['Null'] != 0].index)
dataFile[nullList].dtypes

# Feature Transformation
# Replace nan with most frequent value in these columns
# Columns: MC, SYMBOL, Feature_type, Feature, BIOTYPE, Amino_acids, Codons, STRAND

for x in [
    'MC',
    'SYMBOL',
    'Feature_type',
    'Feature',
    'BIOTYPE',
    'STRAND',
    'Amino_acids',
    'Codons',
    ]:
    dataFile[x].fillna(dataFile[x].mode()[0], inplace=True)

# Replace the nan value in LoFtool column with mean

dataFile['LoFtool'].fillna(dataFile['LoFtool'].mean(), inplace=True)

# check NULL values in a data frame

dataFile.isnull().sum()

# Look at the number of unique values each variable takes, and then create
# and then create list variables for numeric, binary, categorical, and ordinal variables.

dt = pd.DataFrame([[str(i), dataFile[i].dtypes == 'object'] for i in
                  dataFile.columns], columns=['Variable', 'Object Type'
                  ]).set_index('Variable')
columns_object_type = list(dt[dt['Object Type'] == True].index)

# Unique value on each column in dataframe

df_data = dataFile[columns_object_type]
df_unique_values = pd.DataFrame([[i, len(df_data[i].unique())] for i in
                                df_data.columns], columns=['Variable',
                                'Unique Values']).set_index('Variable')
df_unique_values

# Check which variables are binary

variables_bin = list(df_unique_values[df_unique_values['Unique Values']
                     == 2].index)
variables_bin

# Check which variables are categorical

variables_categorical = list(df_unique_values[df_unique_values['Unique Values']
                     > 2].index)
variables_categorical

# Apply function with lambda along the row

for col in variables_categorical:
    dataFile[col] = dataFile[col].apply(lambda x: str(x))

dataFile[variables_categorical].dtypes

# numeric

variables_numeric = list(set(dataFile.columns)
                         - set(variables_categorical)
                         - set(variables_bin))
dataFile[variables_numeric].dtypes

# LabelBinarizer makes this process easy with the transform method.
# Accepts Categorical data as input and returns an Numpy array.
# Encode target labels with value between 0 and n_classes-1.
# To encode target values, i.e. y , and not the input X

(lb, le) = (LabelBinarizer(), LabelEncoder())

# Encode target labels ordinary variables

for col in variables_categorical:
    dataFile[col] = le.fit_transform(dataFile[col])

# Encode target labels ordinary variables encoding binary variables

for col in variables_bin:
    dataFile[col] = lb.fit_transform(dataFile[col])

dataFile.sample(5)

# Display dataFrame as heatmap

plt.figure(figsize=(30, 15))
sns.heatmap(dataFile.corr(), annot=True, linewidths=.5,
            cmap=plt.cm.cool)

# Drop the ALT and MC columns that are strongly correlated
# Correlation for Allele with ALT and Consequence with MC are above 0.8

dataFile.drop(['ALT', 'MC'], axis=1, inplace=True)
variables_categorical.remove('ALT')
variables_categorical.remove('MC')

# Transform features by scaling each feature to a given range.
# The default range for the feature returned by MinMaxScaler is 0 to 1.

mm = MinMaxScaler()
for column in [variables_categorical + variables_numeric]:
    dataFile[column] = mm.fit_transform(dataFile[column])

# counts = dataFile.nunique()
# counts

print(dataFile['CLASS'].value_counts()[0.])
print(dataFile['CLASS'].value_counts()[1.])

feature_columns = list(dataFile.columns)

feature_columns.remove('CLASS')

# Split the data into test and train data sets
# Using StratifiedShuffleSplit so proportion of distribution of
# class labels is almost even between train and test dataset.

# Using StratifiedShuffleSplit() to get the split indexes

sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)

(train_index, test_index) = next(sss.split(dataFile[feature_columns],
                                 dataFile.CLASS))

# Creating dataframes

X_train = dataFile.loc[train_index, feature_columns]
y_train = dataFile.loc[train_index, 'CLASS']

X_test = dataFile.loc[test_index, feature_columns]
y_test = dataFile.loc[test_index, 'CLASS']
(len(X_test), len(X_train))

from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler()
X_resampled_under, y_resampled_under =rus.fit_resample(X_train, y_train)
X_train = X_resampled_under
y_train = y_resampled_under

# Get feature columns count
len(feature_columns)

# Use MLP classifier to train a neural network using backprogation algorithm.
# We will compare results from this algorithm with results from manually created backpropagation algorithm

# Initialize MLP classifier (1 hidden layer)
neuralNet = MLPClassifier(hidden_layer_sizes=(16), activation='relu', solver='sgd', learning_rate='adaptive', learning_rate_init=0.1, max_iter=100)

neuralNet2 = MLPClassifier(hidden_layer_sizes=(16), activation='relu', solver='sgd', learning_rate='adaptive', learning_rate_init=0.01, max_iter=100)

neuralNet3 = MLPClassifier(hidden_layer_sizes=(16), activation='tanh', solver='sgd', learning_rate='adaptive', learning_rate_init=0.1, max_iter=100)

neuralNet4 = MLPClassifier(hidden_layer_sizes=(16), activation='tanh', solver='sgd', learning_rate='adaptive', learning_rate_init=0.01, max_iter=100)

neuralNet5 = MLPClassifier(hidden_layer_sizes=(16), activation='logistic', solver='sgd', learning_rate='adaptive', learning_rate_init=0.1, max_iter=100)

neuralNet6 = MLPClassifier(hidden_layer_sizes=(16), activation='logistic', solver='sgd', learning_rate='adaptive', learning_rate_init=0.01, max_iter=100)

# Fit neural networks to the training data
neuralNet.fit(X_train, y_train)

neuralNet2.fit(X_train, y_train)

neuralNet3.fit(X_train, y_train)

neuralNet4.fit(X_train, y_train)

neuralNet5.fit(X_train, y_train)

neuralNet6.fit(X_train, y_train)

# Use trained neural networks to generate predictions
predict_y_train = neuralNet.predict(X_train)
predict_y_test = neuralNet.predict(X_test)

predict_y_train2 = neuralNet2.predict(X_train)
predict_y_test2 = neuralNet2.predict(X_test)

predict_y_train3 = neuralNet3.predict(X_train)
predict_y_test3 = neuralNet3.predict(X_test)

predict_y_train4 = neuralNet4.predict(X_train)
predict_y_test4 = neuralNet4.predict(X_test)

predict_y_train5 = neuralNet5.predict(X_train)
predict_y_test5 = neuralNet5.predict(X_test)

predict_y_train6 = neuralNet6.predict(X_train)
predict_y_test6 = neuralNet6.predict(X_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

# Evaluation - Confusion Matrix Display - Training Data
conMtrxTrain = confusion_matrix(y_train, predict_y_train, labels=neuralNet.classes_)
conMtrxDisplayTrain = ConfusionMatrixDisplay(confusion_matrix=conMtrxTrain, display_labels=neuralNet.classes_)
conMtrxDisplayTrain.plot()
plt.show()

conMtrxTrain2 = confusion_matrix(y_train, predict_y_train2, labels=neuralNet2.classes_)
conMtrxDisplayTrain2 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTrain2, display_labels=neuralNet2.classes_)
conMtrxDisplayTrain2.plot()
plt.show()

conMtrxTrain3 = confusion_matrix(y_train, predict_y_train3, labels=neuralNet3.classes_)
conMtrxDisplayTrain3 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTrain3, display_labels=neuralNet3.classes_)
conMtrxDisplayTrain3.plot()
plt.show()

conMtrxTrain4 = confusion_matrix(y_train, predict_y_train4, labels=neuralNet4.classes_)
conMtrxDisplayTrain4 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTrain4, display_labels=neuralNet4.classes_)
conMtrxDisplayTrain4.plot()
plt.show()

conMtrxTrain5 = confusion_matrix(y_train, predict_y_train5, labels=neuralNet5.classes_)
conMtrxDisplayTrain5 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTrain5, display_labels=neuralNet5.classes_)
conMtrxDisplayTrain5.plot()
plt.show()

conMtrxTrain6 = confusion_matrix(y_train, predict_y_train6, labels=neuralNet6.classes_)
conMtrxDisplayTrain6 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTrain6, display_labels=neuralNet6.classes_)
conMtrxDisplayTrain6.plot()
plt.show()

# Evaluation - Confusion Matrix Display - Test Data
conMtrxTest = confusion_matrix(y_test, predict_y_test, labels=neuralNet.classes_)
conMtrxDisplayTest = ConfusionMatrixDisplay(confusion_matrix=conMtrxTest, display_labels=neuralNet.classes_)
conMtrxDisplayTest.plot()
plt.show()

conMtrxTest2 = confusion_matrix(y_test, predict_y_test2, labels=neuralNet2.classes_)
conMtrxDisplayTest2 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTest2, display_labels=neuralNet2.classes_)
conMtrxDisplayTest2.plot()
plt.show()

conMtrxTest3 = confusion_matrix(y_test, predict_y_test3, labels=neuralNet3.classes_)
conMtrxDisplayTest3 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTest3, display_labels=neuralNet3.classes_)
conMtrxDisplayTest3.plot()
plt.show()

conMtrxTest4 = confusion_matrix(y_test, predict_y_test4, labels=neuralNet4.classes_)
conMtrxDisplayTest4 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTest4, display_labels=neuralNet4.classes_)
conMtrxDisplayTest4.plot()
plt.show()

conMtrxTest5 = confusion_matrix(y_test, predict_y_test5, labels=neuralNet5.classes_)
conMtrxDisplayTest5 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTest5, display_labels=neuralNet5.classes_)
conMtrxDisplayTest5.plot()
plt.show()

conMtrxTest6 = confusion_matrix(y_test, predict_y_test6, labels=neuralNet6.classes_)
conMtrxDisplayTest6 = ConfusionMatrixDisplay(confusion_matrix=conMtrxTest6, display_labels=neuralNet6.classes_)
conMtrxDisplayTest6.plot()
plt.show()

# Evaluation - Training Accuracy

# Get sum along diagonal of matrix (for total correct predictions)
diagMtrxSumTrain = conMtrxTrain.trace()

# Get sum of all matrix elements (for total predictions)
totMtrxSumTrain = conMtrxTrain.sum()

# Print accuracy
accTrain = diagMtrxSumTrain / totMtrxSumTrain
print('Training Accuracy 1 = ' + str(accTrain))

diagMtrxSumTrain2 = conMtrxTrain2.trace()
totMtrxSumTrain2 = conMtrxTrain2.sum()
accTrain2 = diagMtrxSumTrain2 / totMtrxSumTrain2
print('Training Accuracy 2 = ' + str(accTrain2))

diagMtrxSumTrain3 = conMtrxTrain3.trace()
totMtrxSumTrain3 = conMtrxTrain3.sum()
accTrain3 = diagMtrxSumTrain3 / totMtrxSumTrain3
print('Training Accuracy 3 = ' + str(accTrain3))

diagMtrxSumTrain4 = conMtrxTrain4.trace()
totMtrxSumTrain4 = conMtrxTrain4.sum()
accTrain4 = diagMtrxSumTrain4 / totMtrxSumTrain4
print('Training Accuracy 4 = ' + str(accTrain4))

diagMtrxSumTrain5 = conMtrxTrain5.trace()
totMtrxSumTrain5 = conMtrxTrain5.sum()
accTrain5 = diagMtrxSumTrain5 / totMtrxSumTrain5
print('Training Accuracy 5 = ' + str(accTrain5))

diagMtrxSumTrain6 = conMtrxTrain6.trace()
totMtrxSumTrain6 = conMtrxTrain6.sum()
accTrain6 = diagMtrxSumTrain6 / totMtrxSumTrain6
print('Training Accuracy 6 = ' + str(accTrain6))

# Evaluation - Test Accuracy

# Get sum along diagonal of matrix (for total correct predictions)
diagMtrxSumTest = conMtrxTest.trace()

# Get sum of all matrix elements (for total predictions)
totMtrxSumTest = conMtrxTest.sum()

# Print accuracy
accTest = diagMtrxSumTest / totMtrxSumTest
print('Test Accuracy 1 = ' + str(accTest))

diagMtrxSumTest2 = conMtrxTest2.trace()
totMtrxSumTest2 = conMtrxTest2.sum()
accTest2 = diagMtrxSumTest2 / totMtrxSumTest2
print('Test Accuracy 2 = ' + str(accTest2))

diagMtrxSumTest3 = conMtrxTest3.trace()
totMtrxSumTest3 = conMtrxTest3.sum()
accTest3 = diagMtrxSumTest3 / totMtrxSumTest3
print('Test Accuracy 3 = ' + str(accTest3))

diagMtrxSumTest4 = conMtrxTest4.trace()
totMtrxSumTest4 = conMtrxTest4.sum()
accTest4 = diagMtrxSumTest4 / totMtrxSumTest4
print('Test Accuracy 4 = ' + str(accTest4))

diagMtrxSumTest5 = conMtrxTest5.trace()
totMtrxSumTest5 = conMtrxTest5.sum()
accTest5 = diagMtrxSumTest5 / totMtrxSumTest5
print('Test Accuracy 5 = ' + str(accTest5))

diagMtrxSumTest6 = conMtrxTest6.trace()
totMtrxSumTest6 = conMtrxTest6.sum()
accTest6 = diagMtrxSumTest6 / totMtrxSumTest6
print('Test Accuracy 6 = ' + str(accTest6))

# Evaluation - Classification Report - Train Data
print('Classification Report on Training Data 1')
print(classification_report(y_train, predict_y_train))

print('Classification Report on Training Data 2')
print(classification_report(y_train, predict_y_train2))

print('Classification Report on Training Data 3')
print(classification_report(y_train, predict_y_train3))

print('Classification Report on Training Data 4')
print(classification_report(y_train, predict_y_train4))

print('Classification Report on Training Data 5')
print(classification_report(y_train, predict_y_train5))

print('Classification Report on Training Data 6')
print(classification_report(y_train, predict_y_train6))

# Evaluation - Classification Report - Test Data
print('Classification Report on Test Data 1')
print(classification_report(y_test, predict_y_test))

print('Classification Report on Test Data 2')
print(classification_report(y_test, predict_y_test2))

print('Classification Report on Test Data 3')
print(classification_report(y_test, predict_y_test3))

print('Classification Report on Test Data 4')
print(classification_report(y_test, predict_y_test4))

print('Classification Report on Test Data 5')
print(classification_report(y_test, predict_y_test5))

print('Classification Report on Test Data 6')
print(classification_report(y_test, predict_y_test6))

"""# Neural Network model

## Layer
"""

class Layer:
  def __init__(self, ip_size, op_size):
    self.bias = np.random.rand(1, op_size) - 0.5
    self.wgts = np.random.rand(ip_size, op_size) - 0.5

  def for_prop(self, ip_data):
    self.input = ip_data
    self.output = np.dot(self.input, self.wgts) + self.bias
    return self.output

  def back_prop(self, op_err, lr):
    ip_err = np.dot(op_err, self.wgts.T)
    wgts_err = np.dot(self.input.T, op_err)

    self.wgts -= lr * wgts_err
    self.bias -= lr * op_err
    return ip_err

"""## Activation"""

class Activation:
  def __init__(self, activation_function, activation_derivative_function):
    self.activation_derivative_function = activation_derivative_function
    self.activation_function = activation_function

  def for_prop(self, ip_data):
    self.input = ip_data
    self.output = self.activation_function(self.input)
    return self.output

  def back_prop(self, op_err, lr):
    return self.activation_derivative_function(self.input) * op_err

"""## Activation Functions"""

def tanh(x):
  return np.tanh(x);

def tanh_derivative(x):
  return 1-np.tanh(x)**2;

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return np.exp(-x) / (1 + np.exp(-x))**2

def relu(x):
    return np.maximum(x, 0)

def relu_derivative(x):
    return np.array(x >= 0).astype('int')

"""## Loss Functions"""

def mean_square_err(y_true, y_pred):
    return np.mean(np.power(y_true-y_pred, 2));

def mean_square_err_derivative(y_true, y_pred):
    return 2*(y_pred-y_true)/y_true.size;

"""## Network"""

class NeuralNetwork:
  def __init__(self, loss, loss_derivative, layers):
    self.loss = loss
    self.loss_derivative = loss_derivative
    self.layers = layers

  def predict(self, ip_data):
    result = []
    sampl_size = len(ip_data)
    for i in range(sampl_size):
      output = ip_data[i]
      for layer in self.layers:
        output = layer.for_prop(output)
      result.append(output)
    return result

  def fit(self, x_train, y_train, epoch, lr):
    sampl_size = len(x_train)
    for i in range(epoch):
      err = 0
      for j in range(sampl_size):
        output = x_train[j]
        for layer in self.layers:
          output = layer.for_prop(output)

        error = self.loss_derivative(y_train[j], output)
        for layer in reversed(self.layers):
          error = layer.back_prop(error, lr)

        err += self.loss(y_train[j], output)

      # Average error on all sampl_size
      err /= sampl_size
      print('epoch %d/%d   error=%f' % (i+1, epoch, err))

"""## Network Initialization"""

layers = [
  Layer(16, 10),
  Activation(relu, relu_derivative),
  Layer(10, 1),
  Activation(relu, relu_derivative),
]
nnet = NeuralNetwork(mean_square_err, mean_square_err_derivative, layers)

"""## Fitting"""

X_train = dataFile.loc[train_index, feature_columns]
y_train = dataFile.loc[train_index, 'CLASS']

X_test = dataFile.loc[test_index, feature_columns]
y_test = dataFile.loc[test_index, 'CLASS']
(len(X_test), len(X_train))

from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler()
X_resampled_under, y_resampled_under =rus.fit_resample(X_train, y_train)
X_train = X_resampled_under
y_train = y_resampled_under

# shuffle the training data
from sklearn.utils import shuffle
X_train, y_train = shuffle(X_train, y_train)


aX_train = X_train.to_numpy()
aX_train = aX_train.reshape(aX_train.shape[0], 1, 16)

ay_train = y_train.to_numpy().reshape(y_train.shape[0],1)
ay_train = ay_train.reshape(ay_train.shape[0], 1, 1)

nnet.fit(aX_train, ay_train, epoch=5, lr=0.01)



y_train

"""## Predict"""

aX_test = X_test.to_numpy()
aX_test = aX_test.reshape(aX_test.shape[0], 1, 16)
output = nnet.predict(aX_test)

predict_y = np.array(output)
ay_test = y_test.to_numpy()
ay_test = ay_test.reshape(ay_test.shape[0], 1, 1)

apredict_y = predict_y.reshape(predict_y.shape[0], 1)
aay_test = ay_test.reshape(ay_test.shape[0], 1)

"""## Accuracy"""

np.unique(apredict_y.round())
print(apredict_y[20:])

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
labels = [0., 1.]
conMtrx = confusion_matrix(aay_test, apredict_y.round(), labels=labels)
conMtrxDisplay = ConfusionMatrixDisplay(confusion_matrix=conMtrx, display_labels=labels)
conMtrxDisplay.plot()
plt.show()

# Evaluation - Accuracy

# Get sum along diagonal of matrix (for total correct predictions)
diagMtrxSum = conMtrx.trace()

# Get sum of all matrix elements (for total predictions)
totMtrxSum = conMtrx.sum()

# Print accuracy
acc = diagMtrxSum / totMtrxSum
print('Accuracy = ' + str(acc))

"""## Model Eval"""

layers = {
  "relu": [
    Layer(16, 10),
    Activation(relu, relu_derivative),
    Layer(10, 5),
    Activation(relu, relu_derivative),
    Layer(5, 1),
    Activation(relu, relu_derivative),
    # Layer(10, 1),
    # Activation(sigmoid, sigmoid_derivative),
  ],

  "tanh": [
    Layer(16, 10),
    Activation(tanh, tanh_derivative),
    Layer(10, 5),
    Activation(tanh, tanh_derivative),
    Layer(5, 1),
    Activation(tanh, tanh_derivative),
    # Layer(10, 1),
    # Activation(sigmoid, sigmoid_derivative),
  ],

  "sigmoid": [
      Layer(16, 10),
      Activation(sigmoid, sigmoid_derivative),
      Layer(10, 5),
      Activation(sigmoid, sigmoid_derivative),
      Layer(5, 1),
      Activation(sigmoid, sigmoid_derivative),
      # Layer(10, 1),
      # Activation(sigmoid, sigmoid_derivative),
    ]
}

lrs = [0.1]

epochs = [5]

for act, layer in layers.items():
  for lr in lrs:
    for epoch in epochs:
      # print("Activation function: " + act + " lr: " + lr + " epoch ")
      model_type = ' | '.join(['Activation: ' + act, 'Learning Rate: ' + str(lr), 'Epochs: ' + str(epoch)])
      print(model_type)

      nnet = NeuralNetwork(mean_square_err, mean_square_err_derivative, layer)

      aX_train = X_train.to_numpy()
      aX_train = aX_train.reshape(aX_train.shape[0], 1, 16)

      ay_train = y_train.to_numpy().reshape(y_train.shape[0],1)
      ay_train = ay_train.reshape(ay_train.shape[0], 1, 1)

      nnet.fit(aX_train, ay_train, epoch=epoch, lr=lr)


      # Predict
      aX_test = X_test.to_numpy()
      aX_test = aX_test.reshape(aX_test.shape[0], 1, 16)
      output = nnet.predict(aX_test)

      predict_y = np.array(output)
      ay_test = y_test.to_numpy()
      ay_test = ay_test.reshape(ay_test.shape[0], 1, 1)

      apredict_y = predict_y.reshape(predict_y.shape[0], 1)
      aay_test = ay_test.reshape(ay_test.shape[0], 1)
      apredict_y = apredict_y.round()

      from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
      labels = [0., 1.]
      conMtrx = confusion_matrix(aay_test, apredict_y, labels=labels)
      conMtrxDisplay = ConfusionMatrixDisplay(confusion_matrix=conMtrx, display_labels=labels)
      conMtrxDisplay.plot()
      plt.show()

      # Evaluation - Accuracy

      # Get sum along diagonal of matrix (for total correct predictions)
      diagMtrxSum = conMtrx.trace()

      # Get sum of all matrix elements (for total predictions)
      totMtrxSum = conMtrx.sum()

      # Print accuracy
      accuracy = diagMtrxSum / totMtrxSum


      # from sklearn.metrics import accuracy_score
      # accuracy = accuracy_score(aay_test, apredict_y)


      print('Accuracy = ' + str(accuracy))
      print(classification_report(aay_test, apredict_y))
      print()